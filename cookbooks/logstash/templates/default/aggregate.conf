input {
  file {
    type => "nginx"
    path => "/var/log/nginx/*"
    exclude => "*.gz"
  }
}
filter {
  if [type] == "nginx" {
    grok {
      match => { "message" => "%{IPORHOST:clientip} (?:-|%{USER:ident}) (?:-|%{USER:auth}) \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|-)\" %{NUMBER:response} (?:-|%{NUMBER:bytes})" }
    }
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    aggregate {
      task_id => "%{host}"
      code => "map['answer'] ||= 0 ;
        map['answer2'] ||= 0 ;
        map['answer2'] += 1 ;
        map['answer'] += 1 ;
        map['arrayofresponse'] ||= [];
        map['arrayofbytes'] ||= [];
        map['arrayofresponse'] << event.get('response');
        map['arrayofbytes'] << event.get('bytes')
        map['answer'] = map['arrayofresponse'].length
        map['answer2'] = (map['arrayofbytes'].map(&:to_i).sum)/(map['arrayofbytes'].length)"
      push_map_as_event_on_timeout => true
      timeout => 20 # 1 hour timeout, user activity will be considered finished one hour after the first event, even if events keep coming
      timeout_tags => ['_aggregatetimeout']
    }
  }
}
output {
  elasticsearch { hosts => ["localhost:9200"] }
  stdout { codec => rubydebug }
}